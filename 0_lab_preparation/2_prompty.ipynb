{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Prompty\n",
    "\n",
    "Microsoft Prompty is a tool designed to help developers create, manage, and evaluate prompts for LLMs more efficiently. It works within the VSCode environment and is especially useful for refining AI interactions in GenAI pplications. <br>\n",
    "Prompty provides a standardized format (using markdown) for defining prompts, making it easier to understand, share, and debug. It allows developers to quickly prototype\n",
    "\n",
    "-   Reference: https://microsoft.github.io/promptflow/tutorials/prompty-quickstart.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.tracing import start_trace\n",
    "\n",
    "# start a trace session, and print a url for user to check trace\n",
    "start_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection override\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration, OpenAIModelConfiguration\n",
    "\n",
    "# override configuration with AzureOpenAIModelConfiguration\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=\"${env:AZURE_OPENAI_ENDPOINT}\",  # Use ${env:<ENV_NAME>} to surround the environment variable name.\n",
    "    api_key=\"${env:AZURE_OPENAI_API_KEY}\",\n",
    "    api_version=\"${env:AZURE_OPENAI_API_VERSION}\",\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "override_model = {\"configuration\": configuration, \"parameters\": {\"max_tokens\": 512}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import Prompty\n",
    "\n",
    "# load prompty as a flow\n",
    "f = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "\n",
    "# execute the flow as function\n",
    "result = f(question=\"What is the capital of Seoul?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Prompty.load(source=\"./prompty/korean.prompty\", model=override_model)\n",
    "\n",
    "context = \"\"\"\n",
    "알파인 익스플로러 텐트는 탈착식 칸막이가 있어 프라이버시를 보장합니다, \n",
    "통풍을 위한 수많은 메쉬 창과 조절 가능한 통풍구, 그리고 \n",
    "방수 설계가 특징입니다. 아웃도어 필수품을 보관할 수 있는 내장형 기어 로프트도 \n",
    "장비 로프트가 내장되어 있습니다. 요컨대, 프라이버시, 편안함, \n",
    "편리함이 조화를 이루고 있어 자연 속 제2의 집과도 같은 숙소입니다!\n",
    "\"\"\"\n",
    "result = f(firstName=\"Hyo\", context=context, question=\"텐트에 대해 어떤 점이 궁금하신가요?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Prompty.load(source=\"./prompty/basic.prompty\", model=override_model)\n",
    "eval_flow = Prompty.load(\"./prompty/eval.prompty\", model=override_model)\n",
    "\n",
    "question = \"What is the capital of South Korea?\"\n",
    "ground_truth = \"Seoul\"\n",
    "\n",
    "result = flow(question=question)\n",
    "eval_result = eval_flow(question=question, ground_truth=ground_truth, answer=result)\n",
    "\n",
    "print(f\"result: {result}\")\n",
    "print(f\"eval_result: {eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"Korean\"\n",
    "f = Prompty.load(\"./prompty/chat.prompty\", model=override_model)\n",
    "\n",
    "chat_history = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a factual chatbot that is also sarcastic.\"}, \n",
    "    {\"role\": \"user\", \"content\": \"How far is the Moon from Earth?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"384,400 kilometers\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"Around 384,400 kilometers. Give or take a few, like that really matters.\"}\n",
    "]\n",
    "question = f\"Can you speak more scientifically in {LANGUAGE}?\"\n",
    "result = f(chat_history=chat_history, question=question)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
