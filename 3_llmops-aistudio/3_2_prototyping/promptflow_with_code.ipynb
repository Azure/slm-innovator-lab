{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run chat flows using Promptflow Python SDK \n",
    "\n",
    "### Overview\n",
    "Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality. \n",
    "\n",
    "In this hands-on, you will be able to:\n",
    "Create flows that link fine-tuned phi3.5 endpoint(Python code) and gpt model in a executable workflow.\n",
    "Debug and iterate your flows, especially tracing interaction with LLMs with ease.\n",
    "\n",
    "\n",
    "#### 1. Set up Promptflow client with Credential and configuration\n",
    "#### 2. Create a new chat flow by providing the flow name and description.\n",
    "#### 3. Run Basic Promptflow with questions to compare models\n",
    "#### 4. Run Context Added Promptflow with the outdoor questions \n",
    "#### 5. Use serverless endpoint to run the Promptflow with context\n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d4d3dd0-79d4-40cf-a94e-b4154812c6ca\n",
      "slm-innovator-rg\n",
      "slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import required libraries\n",
    "from promptflow.azure import PFClient\n",
    "from promptflow.entities import Run\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, EnvironmentCredential, InteractiveBrowserCredential\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "load_dotenv()\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(config[\"subscription_id\"])\n",
    "print(config[\"resource_group\"])\n",
    "print(config[\"workspace_name\"]) # Azure AI Studio project name which is not the same as the Azure ML workspace name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_status(pf_azure_client:PFClient, run_result:Run):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = pf_azure_client.runs.get(run_result).status\n",
    "        if status == \"Preparing\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Completed\" and status != \"Failed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = pf_azure_client.runs.get(run_result).status\n",
    "        pbar.update(1)\n",
    "        print(\"Promptflow Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up Promptflow client with Credential and configuration\n",
    "- Create a promptflow client with the credential and configuration. You need to set the `config.json` file with subscription_id, resource_group and workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure AI Studio Workspace: slm-pjt1\n",
      "Workspace Location: eastus\n",
      "Workspace ID: /subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourceGroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
    "    credential = InteractiveBrowserCredential()\n",
    "# if you cannot use DefaultAzureCredential and InteractiveBrowserCredential you need to set up the Managed identity in your .env file\n",
    "\n",
    "pf_azure_client = PFClient.from_config(credential=credential, path=\"./config.json\")\n",
    "\n",
    "# pf_azure_client = PFClient(credential=credential, \n",
    "#                            subscription_id=\"your subscription id\", \n",
    "#                            resource_group_name=\"your resource group name\", \n",
    "#                            workspace_name=\"your workspace name\")            \n",
    "\n",
    "try:\n",
    "    workspace = pf_azure_client.ml_client.workspaces.get(name=config[\"workspace_name\"])\n",
    "    print(f\"Connected to Azure AI Studio Workspace: {workspace.name}\")\n",
    "    print(f\"Workspace Location: {workspace.location}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Failed to connect to Azure ML Workspace: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the exist connections\n",
    "- currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.client import PFClient\n",
    "from promptflow.entities import AzureOpenAIConnection, CustomConnection\n",
    "\n",
    "# Get a pf client to get connections\n",
    "# currently we only support create connection in Azure AI, ML Studio UI\n",
    "pf = PFClient()\n",
    "try:\n",
    "    pf.connections.list()\n",
    "    for connection in pf.connections.list():\n",
    "        print(connection)\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a new chat flow by providing the flow name and description.\n",
    "- Create a new chat flow by providing the flow name and description. You can view and clone the flow on Azure AI studio UI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storage Blob Data Contributor, Storage File Data Privileged Contributor role을 managed Identity / service principal / InteractiveBrowserCredential 에게 부여하면 아래 코드를 실행할 수 있습니다.\n",
    "pf_azure_client.flows.create_or_update(flow=\"chat/\", type=\"chat\", display_name=\"comparison flow created from python sdk\", description=\"fine-tuned model comparison flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run Basic Promptflow with questions to compare models\n",
    "- Run the Promptflow with the simple questions such as \"What is the capital of France?\" and compare the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chat (0.04 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36807/36807 [00:00<00:00, 527927.57it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-10-25 14:13:57 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-10-25 14:13:57 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_variant_0_20241025_141356_267978/details?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat\"\n",
    "data_path = \"./data/questions_basic.jsonl\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\"\n",
    "}\n",
    "\n",
    "run_result = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path,\n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_with_data\",\n",
    "    tags={\"chat_with_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [01:13<02:27, 73.76s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [01:24<00:36, 36.87s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:03<00:00, 81.04s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the center of Seoul?</td>\n",
       "      <td>0</td>\n",
       "      <td>The center of Seoul is often considered to be...</td>\n",
       "      <td>The center of Seoul is often considered to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>1</td>\n",
       "      <td>The capital of France is Paris. Paris is the ...</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me about the brief history of Microsoft</td>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft started in 1975 by Bill Gates and P...</td>\n",
       "      <td>Microsoft was founded by Bill Gates and Paul A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who wrote Romeo and Juliet?</td>\n",
       "      <td>3</td>\n",
       "      <td>William Shakespeare wrote \"Romeo and Juliet.\"...</td>\n",
       "      <td>William Shakespeare wrote \"Romeo and Juliet.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does HTML stand for?</td>\n",
       "      <td>4</td>\n",
       "      <td>HTML stands for HyperText Markup Language. It...</td>\n",
       "      <td>HTML stands for HyperText Markup Language.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>5</td>\n",
       "      <td>The Mona Lisa was painted by Leonardo da Vinc...</td>\n",
       "      <td>Leonardo da Vinci.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>6</td>\n",
       "      <td>Jupiter is the largest planet in our solar sy...</td>\n",
       "      <td>Jupiter is the largest planet in our solar sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who won the Nobel Prize in Literature in 2024?</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>I'm sorry, but I don't have information on Nob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inputs.question  \\\n",
       "outputs.line_number                                                    \n",
       "0                                       what is the center of Seoul?   \n",
       "1                                     What is the capital of France?   \n",
       "2                       Tell me about the brief history of Microsoft   \n",
       "3                                        Who wrote Romeo and Juliet?   \n",
       "4                                          What does HTML stand for?   \n",
       "5                                         Who painted the Mona Lisa?   \n",
       "6                    What is the largest planet in our solar system?   \n",
       "7                     Who won the Nobel Prize in Literature in 2024?   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "5                                     5   \n",
       "6                                     6   \n",
       "7                                     7   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     The center of Seoul is often considered to be...   \n",
       "1                     The capital of France is Paris. Paris is the ...   \n",
       "2                     Microsoft started in 1975 by Bill Gates and P...   \n",
       "3                     William Shakespeare wrote \"Romeo and Juliet.\"...   \n",
       "4                     HTML stands for HyperText Markup Language. It...   \n",
       "5                     The Mona Lisa was painted by Leonardo da Vinc...   \n",
       "6                     Jupiter is the largest planet in our solar sy...   \n",
       "7                                                                 None   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    The center of Seoul is often considered to be ...  \n",
       "1                                      The capital of France is Paris.  \n",
       "2                    Microsoft was founded by Bill Gates and Paul A...  \n",
       "3                        William Shakespeare wrote \"Romeo and Juliet.\"  \n",
       "4                           HTML stands for HyperText Markup Language.  \n",
       "5                                                   Leonardo da Vinci.  \n",
       "6                    Jupiter is the largest planet in our solar sys...  \n",
       "7                    I'm sorry, but I don't have information on Nob...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Context Added Promptflow with the outdoor questions \n",
    "- Run the Promptflow using the context data and ask the outdoor product related questions to compare the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-25 14:18:17 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-10-25 14:18:17 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_context_variant_0_20241025_141815_867099/details?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat-context\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "run_result_with_context = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_context_data\",\n",
    "    tags={\"chat_with_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:52<01:45, 52.99s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [01:03<00:28, 28.00s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:03<00:00, 81.07s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4 Tent</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>TrailMaster X4 텐트는 4인용으로 설계된 실용적인 캠핑 텐트입니다. 내구...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>저는 AI이므로 실질적으로 기기나 장비를 가지고 있지 않지만, 기타 정보나 제안을...</td>\n",
       "      <td>클라이밍 장비 찾고 계신가요? 😊  \\n암벽화, 카라비너, 하네스 등 다양한 장비가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>트레일마스터 X4 텐트는 강성 폴리에스터로 제작된 4명 용도로 물에 강하게 만들어...</td>\n",
       "      <td>저희 텐트 종류에 대해 설명드릴게요! 🏕️\\n\\n1. **돔 텐트**: 설치가 간편...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>죄송하지만, TrekReady 하이킹 부츠의 가격은 제가 직접 제공할 수 없습니다....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you tell me BaseCamp Folding Table?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BaseCamp 접이식 테이블에 대해 알려드릴게요! 이 테이블은 가볍고 휴대하기 쉬...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                               tell me about your TrailMaster X4 Tent   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "4                              can you tell me BaseCamp Folding Table?   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "4                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                                                                 None   \n",
       "1                     저는 AI이므로 실질적으로 기기나 장비를 가지고 있지 않지만, 기타 정보나 제안을...   \n",
       "2                     트레일마스터 X4 텐트는 강성 폴리에스터로 제작된 4명 용도로 물에 강하게 만들어...   \n",
       "3                                                                 None   \n",
       "4                                                                 None   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    TrailMaster X4 텐트는 4인용으로 설계된 실용적인 캠핑 텐트입니다. 내구...  \n",
       "1                    클라이밍 장비 찾고 계신가요? 😊  \\n암벽화, 카라비너, 하네스 등 다양한 장비가...  \n",
       "2                    저희 텐트 종류에 대해 설명드릴게요! 🏕️\\n\\n1. **돔 텐트**: 설치가 간편...  \n",
       "3                    죄송하지만, TrekReady 하이킹 부츠의 가격은 제가 직접 제공할 수 없습니다....  \n",
       "4                    BaseCamp 접이식 테이블에 대해 알려드릴게요! 이 테이블은 가볍고 휴대하기 쉬...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result_with_context)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use serverless endpoint to run the Promptflow with context\n",
    "- Create a serverless endpoint to run the Promptflow with the context. You can use the endpoint to run the flow with the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deploy your serverless endpoint\n",
    "\n",
    "- go to the Azure AI studio > Model catalog > search phi-3.5 > deply Phi-3.5-mini-instruct as your serverless endpint \n",
    "<br>\n",
    "![serverless endpoint](./images/deploy_serverless_endpoint.jpg)\n",
    "<br>\n",
    "<br>\n",
    "- once the deployment is done, go to Deployments and you can see the endpoint deployed in the endpoint section. Click to check the details and copy key and phi35-mini-instruct: Chat Completion endpoint url\n",
    "![copy connection](./images/copy_connection.jpg)\n",
    "<br>\n",
    "<br>\n",
    "- go to Settings in Azure AI studio > Connections > create a new connection naming phi35-serverless with the copied key and endpoint url\n",
    "![create new serverless connection](./images/create_new_serverless_connection.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-10-25 14:22:27 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-10-25 14:22:27 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_serverless_variant_0_20241025_142226_832733/details?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat-serverless\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "run_serverless_result = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_serverless_context_data\",\n",
    "    tags={\"chat_serverless_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 0/3 [00:00<?, ?step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: NotStarted\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:42<01:24, 42.15s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [00:52<00:23, 23.52s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:13<00:00, 24.58s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_serverless_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4 Tent</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>TrailMaster X4 Tent은 강력한 폴리에스터로 만들어진 활주로 텐트로,...</td>\n",
       "      <td>TrailMaster X4 텐트는 4인용 캠핑 텐트로, 설치가 쉽고 내구성이 뛰어난...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>네, 기술 도구를 가지고 있습니다. 언급하신 계곡 산악 장비에 대해 알려드릴게요:...</td>\n",
       "      <td>클라이밍 장비 찾고 계신가요? 😊 헬멧, 하네스, 카라비너 등 다양한 장비가 있어요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>트레일마스터 X4는 풀 트레프용으로 강력한 고기본으로 구성된 네 명의 사람을 수용...</td>\n",
       "      <td>저희 텐트 컬렉션은 다양합니다! 🏕️ 다양한 크기와 스타일로 캠핑, 하이킹, 글램핑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>트레크리에어 힐크스 야외 복장은 지지와 편안함을 제공합니다. 그러나 구체적인 가격...</td>\n",
       "      <td>TrekReady 하이킹 부츠를 찾으시는군요! 😄 현재 재고 정보는 확인이 안 되지...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you tell me BaseCamp Folding Table?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>4</td>\n",
       "      <td>기본캠프 플랫폼은 48x24인치의 가벼운 알루미늄 테이블로, 펼쳐지는 디자인으로 ...</td>\n",
       "      <td>BaseCamp 접이식 테이블은 가벼우면서도 튼튼한 캠핑 테이블이에요. 설치와 보관...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                               tell me about your TrailMaster X4 Tent   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "4                              can you tell me BaseCamp Folding Table?   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "4                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     TrailMaster X4 Tent은 강력한 폴리에스터로 만들어진 활주로 텐트로,...   \n",
       "1                     네, 기술 도구를 가지고 있습니다. 언급하신 계곡 산악 장비에 대해 알려드릴게요:...   \n",
       "2                     트레일마스터 X4는 풀 트레프용으로 강력한 고기본으로 구성된 네 명의 사람을 수용...   \n",
       "3                     트레크리에어 힐크스 야외 복장은 지지와 편안함을 제공합니다. 그러나 구체적인 가격...   \n",
       "4                     기본캠프 플랫폼은 48x24인치의 가벼운 알루미늄 테이블로, 펼쳐지는 디자인으로 ...   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    TrailMaster X4 텐트는 4인용 캠핑 텐트로, 설치가 쉽고 내구성이 뛰어난...  \n",
       "1                    클라이밍 장비 찾고 계신가요? 😊 헬멧, 하네스, 카라비너 등 다양한 장비가 있어요...  \n",
       "2                    저희 텐트 컬렉션은 다양합니다! 🏕️ 다양한 크기와 스타일로 캠핑, 하이킹, 글램핑...  \n",
       "3                    TrekReady 하이킹 부츠를 찾으시는군요! 😄 현재 재고 정보는 확인이 안 되지...  \n",
       "4                    BaseCamp 접이식 테이블은 가벼우면서도 튼튼한 캠핑 테이블이에요. 설치와 보관...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_serverless_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
