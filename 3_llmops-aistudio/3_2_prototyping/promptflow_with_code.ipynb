{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Run chat flows using Promptflow Python SDK \n",
    "\n",
    "### Overview\n",
    "Prompt flow is a suite of development tools designed to streamline the end-to-end development cycle of LLM-based AI applications, from ideation, prototyping, testing, evaluation to production deployment and monitoring. It makes prompt engineering much easier and enables you to build LLM apps with production quality. \n",
    "\n",
    "In this hands-on, you will be able to:\n",
    "Create flows that link fine-tuned phi3.5 endpoint(Python code) and gpt model in a executable workflow.\n",
    "Debug and iterate your flows, especially tracing interaction with LLMs with ease.\n",
    "\n",
    "\n",
    "#### 1. Create Promptflow client with Credential and configuration\n",
    "#### 2. Run Basic Promptflow with questions to compare models\n",
    "#### 3. Run Context Added Promptflow with the outdoor questions \n",
    "\n",
    "[Note] Please use `Python 3.10 - SDK v2 (azureml_py310_sdkv2)` conda environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d4d3dd0-79d4-40cf-a94e-b4154812c6ca\n",
      "slm-innovator-rg\n",
      "slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Import required libraries\n",
    "from promptflow.azure import PFClient\n",
    "from promptflow.entities import Run\n",
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "from evaluate import run_azure_flow, run_azure_eval_flow\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "with open('./config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(config[\"subscription_id\"])\n",
    "print(config[\"resource_group\"])\n",
    "print(config[\"workspace_name\"]) # Azure AI Studio project name which is not the same as the Azure ML workspace name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Monitor the status of the run_result\n",
    "def monitor_status(pf_azure_client:PFClient, run_result:Run):\n",
    "    with tqdm(total=3, desc=\"Running Status\", unit=\"step\") as pbar:\n",
    "        status = pf_azure_client.runs.get(run_result).status\n",
    "        if status == \"Preparing\":\n",
    "            pbar.update(1)\n",
    "        while status != \"Completed\":\n",
    "            if status == \"Running\" and pbar.n < 2:\n",
    "                pbar.update(1)\n",
    "            print(f\"Current Status: {status}\")\n",
    "            time.sleep(10)\n",
    "            status = pf_azure_client.runs.get(run_result).status\n",
    "        pbar.update(1)\n",
    "        print(\"Promptflow Running Completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Promptflow client with Credential and configuration\n",
    "- Create a promptflow client with the credential and configuration. You need to set the `config.json` file with subscription_id, resource_group and workspace_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Azure AI Studio Workspace: slm-pjt1\n",
      "Workspace Location: eastus\n",
      "Workspace ID: /subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourceGroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential()\n",
    "# if you cannot use DefaultAzureCredential, you need to set up the environment variables for the service principal\n",
    "# credential = ServicePrincipalCredentials(\n",
    "#     client_id=os.environ[\"AZURE_CLIENT_ID\"],\n",
    "#     secret=os.environ[\"AZURE_CLIENT_SECRET\"],\n",
    "#     tenant=os.environ[\"AZURE_TENANT_ID\"],\n",
    "# )\n",
    "# Check if given credential can get token successfully.\n",
    "credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "pf_azure_client = PFClient.from_config(credential=credential, path=\"./config.json\")\n",
    "\n",
    "# pf_azure_client = PFClient(credential=credential, \n",
    "#                            subscription_id=\"your subscription id\", \n",
    "#                            resource_group_name=\"your resource group name\", \n",
    "#                            workspace_name=\"your workspace name\")            \n",
    "\n",
    "try:\n",
    "    workspace = pf_azure_client.ml_client.workspaces.get(name=config[\"workspace_name\"])\n",
    "    print(f\"Connected to Azure AI Studio Workspace: {workspace.name}\")\n",
    "    print(f\"Workspace Location: {workspace.location}\")\n",
    "    print(f\"Workspace ID: {workspace.id}\")\n",
    "except HttpResponseError as e:\n",
    "    print(f\"Failed to connect to Azure ML Workspace: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the exist connections\n",
    "- currently we only support create connection in Azure AI, ML Studio UI. Check the exiting connections in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auth_mode: key\n",
      "name: ai-slmhub1616907550322_aoai\n",
      "module: promptflow.connections\n",
      "created_date: '2024-10-21 23:44:10.828648+00:00'\n",
      "last_modified_date: '2024-10-21 23:44:10.828648+00:00'\n",
      "type: azure_open_ai\n",
      "api_key: '******'\n",
      "api_base: https://ai-slmhub1616907550322.openai.azure.com/\n",
      "api_type: Azure\n",
      "api_version: 2023-07-01-preview\n",
      "resource_id: \n",
      "  /subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourceGroups/slm-innovator-rg/providers/Microsoft.CognitiveServices/accounts/ai-slmhub1616907550322\n",
      "\n",
      "auth_mode: key\n",
      "name: ai-slmhub1616907550322\n",
      "module: promptflow.connections\n",
      "created_date: '2024-10-21 23:44:10.828648+00:00'\n",
      "last_modified_date: '2024-10-21 23:44:10.828648+00:00'\n",
      "type: azure_ai_services\n",
      "api_key: '******'\n",
      "endpoint: https://ai-slmhub1616907550322.cognitiveservices.azure.com/\n",
      "\n",
      "auth_mode: key\n",
      "name: wsstq75qvfcwosearch\n",
      "module: promptflow.connections\n",
      "created_date: '2024-10-22 08:12:14.702733+00:00'\n",
      "last_modified_date: '2024-10-22 08:12:14.702733+00:00'\n",
      "type: cognitive_search\n",
      "api_key: '******'\n",
      "api_base: https://wsstq75qvfcwo-search.search.windows.net/\n",
      "api_version: 2024-05-01-preview\n",
      "\n",
      "name: phi35-con\n",
      "module: promptflow.connections\n",
      "created_date: '2024-10-23 02:51:08.238822+00:00'\n",
      "last_modified_date: '2024-10-23 02:51:08.238822+00:00'\n",
      "type: custom\n",
      "configs:\n",
      "  endpoint: https://phi3-endpoint-2024-08-27.eastus.inference.ml.azure.com/score\n",
      "secrets: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from promptflow.client import PFClient\n",
    "from promptflow.entities import AzureOpenAIConnection, CustomConnection\n",
    "\n",
    "# Get a pf client to get connections\n",
    "# currently we only support create connection in Azure AI, ML Studio UI\n",
    "pf = PFClient()\n",
    "try:\n",
    "    pf.connections.list()\n",
    "    for connection in pf.connections.list():\n",
    "        print(connection)\n",
    "except (ValueError, TypeError) as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a chat flow using Promptflow client\n",
    "- Create a new chat flow by providing the flow name and description. You can view and clone the flow on Azure AI studio UI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow created successfully:\n",
      "{\n",
      "    \"name\": \"1b85e066-c15e-4532-a873-e78773badc15\",\n",
      "    \"type\": \"chat\",\n",
      "    \"description\": \"fine-tuned model comparison flow\",\n",
      "    \"path\": \"Users/8e2870f5-6900-44d5-a7ca-5892562926fd/promptflow/chat-10-23-2024-13-43-47/flow.dag.yaml\",\n",
      "    \"code\": \"azureml://locations/eastus/workspaces/884cbbaf-4d30-486f-a017-f9265971b9e1/flows/1b85e066-c15e-4532-a873-e78773badc15\",\n",
      "    \"display_name\": \"comparison flow created from python sdk\",\n",
      "    \"owner\": {\n",
      "        \"user_object_id\": \"8e2870f5-6900-44d5-a7ca-5892562926fd\",\n",
      "        \"user_tenant_id\": \"16b3c013-d300-468d-ac64-7eda0820b6d3\",\n",
      "        \"user_name\": \"7ac00d14-31c3-4eac-a9a9-338f6dbd1c98\"\n",
      "    },\n",
      "    \"is_archived\": false,\n",
      "    \"created_date\": \"2024-10-23 13:43:49.700823+00:00\",\n",
      "    \"flow_portal_url\": \"https://ai.azure.com/projectflows/1b85e066-c15e-4532-a873-e78773badc15/884cbbaf-4d30-486f-a017-f9265971b9e1/details/Flow?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Storage Blob Data Contributor, Storage File Data Privileged Contributor role을 managed Identity / service principal / InteractiveBrowserCredential 에게 부여하면 아래 코드를 실행할 수 있습니다.\n",
    "pf_azure_client.flows.create_or_update(flow=\"chat/\", type=\"chat\", display_name=\"comparison flow created from python sdk\", description=\"fine-tuned model comparison flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Basic Promptflow with questions to compare models\n",
    "- Run the Promptflow with the simple questions such as \"What is the capital of France?\" and compare the results of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chat (0.04 MBs): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36388/36388 [00:00<00:00, 555802.79it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-10-23 13:52:23 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-10-23 13:52:23 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chat_variant_0_20241023_135222_031989/details?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "flow_path = \"./chat\"\n",
    "data_path = \"./data/questions_basic.jsonl\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\"\n",
    "}\n",
    "\n",
    "run_result = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path,\n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_with_data\",\n",
    "    tags={\"chat_with_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:00<00:01,  1.65step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Preparing\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [00:21<00:12, 12.66s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:04<00:00, 21.36s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the center of Seoul?</td>\n",
       "      <td>0</td>\n",
       "      <td>Gyeongbokgung Palace is the most prominent hi...</td>\n",
       "      <td>The center of Seoul is often considered to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the capital of France?</td>\n",
       "      <td>1</td>\n",
       "      <td>Paris</td>\n",
       "      <td>The capital of France is Paris.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tell me about the brief history of Microsoft</td>\n",
       "      <td>2</td>\n",
       "      <td>Microsoft was founded on April 4, 1975, by Bi...</td>\n",
       "      <td>Microsoft was founded on April 4, 1975, by Bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who wrote Romeo and Juliet?</td>\n",
       "      <td>3</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>William Shakespeare wrote \"Romeo and Juliet.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does HTML stand for?</td>\n",
       "      <td>4</td>\n",
       "      <td>HTML stands for HyperText Markup Language.</td>\n",
       "      <td>HTML stands for HyperText Markup Language.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Who painted the Mona Lisa?</td>\n",
       "      <td>5</td>\n",
       "      <td>Leonardo da Vinci painted the Mona Lisa.</td>\n",
       "      <td>The Mona Lisa was painted by Leonardo da Vinci.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is the largest planet in our solar system?</td>\n",
       "      <td>6</td>\n",
       "      <td>Jupiter is the largest planet in our solar sy...</td>\n",
       "      <td>The largest planet in our solar system is Jupi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who won the Nobel Prize in Literature in 2024?</td>\n",
       "      <td>7</td>\n",
       "      <td>As of my knowledge cutoff in 2023, I cannot p...</td>\n",
       "      <td>I'm sorry, I don't have that information. You ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     inputs.question  \\\n",
       "outputs.line_number                                                    \n",
       "0                                       what is the center of Seoul?   \n",
       "1                                     What is the capital of France?   \n",
       "2                       Tell me about the brief history of Microsoft   \n",
       "3                                        Who wrote Romeo and Juliet?   \n",
       "4                                          What does HTML stand for?   \n",
       "5                                         Who painted the Mona Lisa?   \n",
       "6                    What is the largest planet in our solar system?   \n",
       "7                     Who won the Nobel Prize in Literature in 2024?   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "5                                     5   \n",
       "6                                     6   \n",
       "7                                     7   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     Gyeongbokgung Palace is the most prominent hi...   \n",
       "1                                                                Paris   \n",
       "2                     Microsoft was founded on April 4, 1975, by Bi...   \n",
       "3                                                  William Shakespeare   \n",
       "4                           HTML stands for HyperText Markup Language.   \n",
       "5                             Leonardo da Vinci painted the Mona Lisa.   \n",
       "6                     Jupiter is the largest planet in our solar sy...   \n",
       "7                     As of my knowledge cutoff in 2023, I cannot p...   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    The center of Seoul is often considered to be ...  \n",
       "1                                      The capital of France is Paris.  \n",
       "2                    Microsoft was founded on April 4, 1975, by Bil...  \n",
       "3                        William Shakespeare wrote \"Romeo and Juliet.\"  \n",
       "4                           HTML stands for HyperText Markup Language.  \n",
       "5                      The Mona Lisa was painted by Leonardo da Vinci.  \n",
       "6                    The largest planet in our solar system is Jupi...  \n",
       "7                    I'm sorry, I don't have that information. You ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result)\n",
    "\n",
    "detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Context Added Promptflow with the outdoor questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading chatwithcontext (0.04 MBs): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38890/38890 [00:00<00:00, 557424.97it/s]\u001b[0m\n",
      "\u001b[39m\n",
      "\n",
      "[2024-10-23 14:29:19 +0000][promptflow][WARNING] - You're using compute session, if it's first time you're using it, it may take a while to build session and you may see 'NotStarted' status for a while. \n",
      "[2024-10-23 14:29:19 +0000][promptflow][WARNING] - The trace Cosmos DB for current workspace/project is not ready yet, your traces might not be logged and stored properly.\n",
      "To enable it, please run `pf config set trace.destination=azureml://subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.MachineLearningServices/workspaces/<workspace-or-project-name>`, prompt flow will help to get everything ready.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portal url: https://ai.azure.com/projectflows/trace/run/chatwithcontext_variant_0_20241023_142917_923363/details?wsid=/subscriptions/3d4d3dd0-79d4-40cf-a94e-b4154812c6ca/resourcegroups/slm-innovator-rg/providers/Microsoft.MachineLearningServices/workspaces/slm-pjt1\n"
     ]
    }
   ],
   "source": [
    "#TODO test https://github.com/microsoft/promptflow/blob/main/examples/flows/chat/chat-with-pdf/chat-with-pdf-azure.ipynb\n",
    "#2. Run a flow with setting (context size 2K)\n",
    "flow_path = \"./chatwithcontext\"\n",
    "data_path = \"./data/questions_outdoor.jsonl\"\n",
    "\n",
    "# get the context from context.json file as str and map it to the column_mapping\n",
    "with open('./data/context_simple.json', 'r') as file:\n",
    "    context = json.load(file)\n",
    "\n",
    "column_mapping = {\n",
    "    \"question\": \"${data.question}\",\n",
    "    \"context\": context.get(\"context\")    \n",
    "}\n",
    "\n",
    "run_result_with_context = pf_azure_client.run(\n",
    "    flow=flow_path,\n",
    "    type=\"chat\",\n",
    "    data=data_path, \n",
    "    column_mapping=column_mapping,\n",
    "    display_name=\"chat_with_context_and_data\",\n",
    "    tags={\"chat_with_context_jsonl\": \"\", \"1st_round\": \"\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  33%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 1/3 [00:00<00:01,  1.44step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Preparing\n",
      "Current Status: Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                                                                                                                                                           | 2/3 [00:22<00:12, 12.93s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n",
      "Current Status: Running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Status: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [04:05<00:00, 81.71s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promptflow Running Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "monitor_status(pf_azure_client, run_result_with_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>inputs.context</th>\n",
       "      <th>inputs.line_number</th>\n",
       "      <th>outputs.phi35_answer</th>\n",
       "      <th>outputs.gpt4o_answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outputs.line_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tell me about your TrailMaster X4</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>🌄 **TrailMaster X4 행복한 산길 여행의 정수!**\\n\\nTrailM...</td>\n",
       "      <td>TrailMaster X4에 대해 알려드릴게요!\\n\\nTrailMaster X4는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any climbing gear?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>아쉽지만, 저는 실제 장비를 가지고 있진 않아요. 😅 하지만 등산 장비에 대해 물어...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you tell me about your selection of tents?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>🌟 테크노 피트와 탐험 소지에 열정을 가진 당신에게, 우리의 옵션 세트에서 테크노...</td>\n",
       "      <td>저희 텐트 종류는 다양해요! 🏕️\\n\\n1. **돔 텐트**: 가벼워서 이동하기 좋...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have TrekReady Hiking Boots? How much i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>죄송하지만, TrekReady 하이킹 부츠의 가격은 정확히 알 수 없어요. 😅 대부...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can you tell me BaseCamp Folding Table?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>BaseCamp 접이식 테이블은 캠핑이나 야외 활동에 적합한 휴대용 테이블이에요. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is your return or exchange policy?</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>저희의 반품 및 교환 정책은 구매 후 30일 이내에 가능합니다. 물품은 사용하지 않...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I would like to return the tent I bought. It i...</td>\n",
       "      <td>TrailMaster X4 Tent is a durable polyester ten...</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>물론이죠! 사용한 텐트라도 문제가 있다면 반품을 도와드릴 수 있습니다. 구매하신 곳...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       inputs.question  \\\n",
       "outputs.line_number                                                      \n",
       "0                                    tell me about your TrailMaster X4   \n",
       "1                                       Do you have any climbing gear?   \n",
       "2                       Can you tell me about your selection of tents?   \n",
       "3                    Do you have TrekReady Hiking Boots? How much i...   \n",
       "4                              can you tell me BaseCamp Folding Table?   \n",
       "5                              What is your return or exchange policy?   \n",
       "6                    I would like to return the tent I bought. It i...   \n",
       "\n",
       "                                                        inputs.context  \\\n",
       "outputs.line_number                                                      \n",
       "0                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "1                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "2                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "3                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "4                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "5                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "6                    TrailMaster X4 Tent is a durable polyester ten...   \n",
       "\n",
       "                     inputs.line_number  \\\n",
       "outputs.line_number                       \n",
       "0                                     0   \n",
       "1                                     1   \n",
       "2                                     2   \n",
       "3                                     3   \n",
       "4                                     4   \n",
       "5                                     5   \n",
       "6                                     6   \n",
       "\n",
       "                                                  outputs.phi35_answer  \\\n",
       "outputs.line_number                                                      \n",
       "0                     🌄 **TrailMaster X4 행복한 산길 여행의 정수!**\\n\\nTrailM...   \n",
       "1                                                                 None   \n",
       "2                     🌟 테크노 피트와 탐험 소지에 열정을 가진 당신에게, 우리의 옵션 세트에서 테크노...   \n",
       "3                                                                 None   \n",
       "4                                                                 None   \n",
       "5                                                                 None   \n",
       "6                                                                 None   \n",
       "\n",
       "                                                  outputs.gpt4o_answer  \n",
       "outputs.line_number                                                     \n",
       "0                    TrailMaster X4에 대해 알려드릴게요!\\n\\nTrailMaster X4는 ...  \n",
       "1                    아쉽지만, 저는 실제 장비를 가지고 있진 않아요. 😅 하지만 등산 장비에 대해 물어...  \n",
       "2                    저희 텐트 종류는 다양해요! 🏕️\\n\\n1. **돔 텐트**: 가벼워서 이동하기 좋...  \n",
       "3                    죄송하지만, TrekReady 하이킹 부츠의 가격은 정확히 알 수 없어요. 😅 대부...  \n",
       "4                    BaseCamp 접이식 테이블은 캠핑이나 야외 활동에 적합한 휴대용 테이블이에요. ...  \n",
       "5                    저희의 반품 및 교환 정책은 구매 후 30일 이내에 가능합니다. 물품은 사용하지 않...  \n",
       "6                    물론이죠! 사용한 텐트라도 문제가 있다면 반품을 도와드릴 수 있습니다. 구매하신 곳...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail = pf_azure_client.get_details(run_result_with_context)\n",
    "\n",
    "detail"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py310_sdkv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
