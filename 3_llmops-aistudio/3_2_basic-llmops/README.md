---
layout: default
title: Lab3.2 Basic LLMOps for your first gen AI application
permalink: /3_2_basic-llmops/
---

# Lab 3.2 Scenario 2: Basic LLMOps for your first gen AI application

## Overview
In this lab, we will learn how to create your basic ochestration flow and automate the build and deployment of your LLMOps flow

### Result
![result](images/large-language-model-operations-prompt-flow-process.png)


### TOC
- 0ï¸âƒ£ Create a standard flow 
- 1ï¸âƒ£ Integrate the phi3 endpoint into Python Node 
- ğŸ§ª Test the Flow locally
- 2ï¸âƒ£ Deploy your flow for real-time inference
- 3ï¸âƒ£ Build basic LLMOps pipeline using Github Actions
- 4ï¸âƒ£ Build advanced LLMOps pipeline for dev, production
- ğŸ—‘ï¸ Clean up resources

For simplicity, we will only go up to step 5 of the diagram at the result figure in this page

### 0ï¸âƒ£ Create a standard flow 
- 
- 
- 

### 1ï¸âƒ£ Integrate the phi3 endpoint into Python Node 
- 
- 

### ğŸ§ª Test the Flow locally
- 
- 


### 2ï¸âƒ£ Deploy your flow for real-time inference
- 
- 

### 3ï¸âƒ£ Build basic LLMOps pipeline using Github Actions
- 
- 
- 


### ğŸ—‘ï¸ Clean up resources


https://learn.microsoft.com/en-us/azure/ai-studio/how-to/flow-deploy 